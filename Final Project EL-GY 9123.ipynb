{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Introduction\n",
    "To implement a SVM classification machine-learning model, l choose the dataset downloaded from https://www.kaggle.com/abcsds/pokemon, which describes Pokémon’s stats and types. \n",
    "Pokémon is a game created by Nintendo in 1996 running in GBA devices. As soon as it released, it conquered the world. During a very long time, people are crazy about this game. However, as Nintendo met a huge problem in developing itself, the influence of this game also decreased as long the advent of intelligent equipment era, people are apt to play games running in their smartphone with huge screen rather than in GBA or some other out-of-time game devices. But, recently, Nintendo Company decided to release this game in smartphone, and this is a huge shock for the people who played this game which we could say it as “This game accompanies their growth”.\n",
    "The reason why I want to choose this one as my dataset I because I am also a big fan of “Pokémon Go” and my objective is to make use of this dataset to help evaluating how good a Pokémon is, which means which sort of type could decide a Pokémon to be a legendary level guy. I hope to use what I have learned to contribute to this memorable stuff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import linear_model\n",
    "import numpy.polynomial.polynomial as poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read pokemon data from dataset\n",
    "pk = pd.read_csv('Pokemon.csv', na_values = ['', ' ', 'NaN', np.nan], index_col = 0)\n",
    "pk = np.array(pk)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# merge two type into one\n",
    "type_merge = []\n",
    "for pair in zip(pk[:,0], pk[:,1]):\n",
    "    pair = set(pair)\n",
    "    type_merge.append(pair)\n",
    "values = np.array(type_merge)\n",
    "# transform types into one hot coding\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "onehot_encoder = OneHotEncoder(sparse = False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "pk = np.delete(pk, [0,1], 1)\n",
    "pk = np.hstack((onehot_encoded, pk))\n",
    "# transform bool to int\n",
    "lb = LabelBinarizer()\n",
    "pk[:,-1] = np.transpose(lb.fit_transform(pk[:,-1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the first 160 rows (20%) to test\n",
    "Xts = pk[:160,:-1]\n",
    "Xtr = pk[161:,:-1]\n",
    "yts = pk[:160,-1]\n",
    "ytr = pk[161:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.981250\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC(probability = False, kernel = \"rbf\", C = 100, gamma = 1, verbose = False)\n",
    "svc.fit(Xtr, ytr.astype(float))\n",
    "yhat = svc.predict(Xts)\n",
    "acc = np.mean(yhat == yts)\n",
    "print('Accuracy = {0:f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read combats data from dataset\n",
    "cb = pd.read_csv('combats.csv', na_values = ['', ' ', 'NaN', np.nan])\n",
    "pk = pd.read_csv('pokemon_new.csv', na_values = ['', ' ', 'NaN', np.nan])\n",
    "pk = np.array(pk)\n",
    "type_merge = []\n",
    "for pair in zip(pk[:,2], pk[:,3]):\n",
    "    pair = set(pair)\n",
    "    type_merge.append(pair)\n",
    "values = np.array(type_merge)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "onehot_encoder = OneHotEncoder(sparse = False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "onehot_len = onehot_encoded.shape[1]\n",
    "pk = np.delete(pk, [1,2,3], 1)\n",
    "pk = np.insert(pk, [1], onehot_encoded, axis = 1)\n",
    "pk = np.delete(pk, -1, 1) # delete the last column which represent whether it is legendary\n",
    "\n",
    "cb = np.array(cb)\n",
    "Xtr_cb = cb[:cb.shape[0]*4//5]\n",
    "Xts_cb = cb[cb.shape[0]*4//5+1:]\n",
    "ytr = []\n",
    "yts = []\n",
    "for pair in Xtr_cb:\n",
    "    if pair[2] == pair[0]: ytr.append(0)\n",
    "    else: ytr.append(1)\n",
    "for pair in Xts_cb:\n",
    "    if pair[2] == pair[0]: yts.append(0)\n",
    "    else: yts.append(1)\n",
    "ytr = np.array(ytr)\n",
    "yts = np.array(yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 1049)\n",
      "(40000,)\n",
      "Accuracy = 0.884088\n",
      "0.464721764628\n"
     ]
    }
   ],
   "source": [
    "Xtr_new = np.zeros((Xtr_cb.shape[0], pk.shape[1]-1+onehot_len))\n",
    "Xts_new = np.zeros((Xts_cb.shape[0], pk.shape[1]-1+onehot_len))\n",
    "for i, pair in enumerate(Xtr_cb):\n",
    "    Xtr_new[i] = np.concatenate((pk[pair[0]-1,1:onehot_len+1], pk[pair[1]-1,1:onehot_len+1], pk[pair[0]-1,onehot_len+1:]-pk[pair[1]-1,onehot_len+1:]))\n",
    "for i, pair in enumerate(Xts_cb):\n",
    "    Xts_new[i] = np.concatenate((pk[pair[0]-1,1:onehot_len+1], pk[pair[1]-1,1:onehot_len+1], pk[pair[0]-1,onehot_len+1:]-pk[pair[1]-1,onehot_len+1:]))\n",
    "regr = linear_model.LinearRegression()\n",
    "print(Xtr_new.shape)\n",
    "print(ytr.shape)\n",
    "regr.fit(Xtr_new, ytr)\n",
    "yhat = regr.predict(Xts_new)\n",
    "for i, num in enumerate(yhat):\n",
    "    if num < 0.5: yhat[i] = 0\n",
    "    else: yhat[i] = 1\n",
    "acc = np.mean(yhat == yts)\n",
    "print('Accuracy = {0:f}'.format(acc))\n",
    "RSS = np.mean((yhat-yts)**2/(np.std(yts)**2))\n",
    "print('Normalized RSS = {0:f}'.format(RSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
